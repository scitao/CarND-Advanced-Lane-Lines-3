{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded saved calibration file\n",
      "[MoviePy] >>>> Building video ../output.mp4\n",
      "[MoviePy] Writing video ../output.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 1199/1200 [13:10<00:00,  1.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: ../output.mp4 \n",
      "\n",
      "CPU times: user 11min 42s, sys: 2min 59s, total: 14min 41s\n",
      "Wall time: 13min 13s\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from camera import corners_unwarp\n",
    "from camera import warp_birds_eye\n",
    "from camera import Calibration\n",
    "\n",
    "from window import find_window_centroids\n",
    "from window import sliding_window\n",
    "\n",
    "from lane_line_tracker import LaneLineTracker\n",
    "\n",
    "from thresholding import get_edge_mask\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# Checkerboard grid pattern\n",
    "PATTERN_SIZE=(9, 6)\n",
    "N_WINDOWS=9\n",
    "\n",
    "# Input image width and height\n",
    "W = 1280\n",
    "H = 720\n",
    "\n",
    "# Perspective transform source and desetination points\n",
    "SOURCE_POINTS = np.float32([\n",
    "    [-100, H], \n",
    "    [W / 2 - 76, H * .625], \n",
    "    [W / 2 + 76, H * .625], \n",
    "    [W + 100, H]\n",
    "])\n",
    "DESTINATION_POINTS = np.float32([\n",
    "    [100, H], \n",
    "    [100, 0], \n",
    "    [W - 100, 0], \n",
    "    [W - 100, H]\n",
    "])    \n",
    "\n",
    "calibration = Calibration('../camera_cal/calibration*.jpg', PATTERN_SIZE, 'calibration.p', output_status=True)\n",
    "calibration.calibrate()\n",
    "\n",
    "video_path = '../harder_challenge_video.mp4'\n",
    "output_path = '../output.mp4'\n",
    "tracker = LaneLineTracker(\n",
    "    video_path, \n",
    "    calibration=calibration, \n",
    "    source_points=SOURCE_POINTS, \n",
    "    destination_points=DESTINATION_POINTS, \n",
    "    output_path=output_path\n",
    ")\n",
    "%time tracker.process_video()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Collect Calibration Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "calibration = Calibration('../camera_cal/calibration*.jpg', PATTERN_SIZE, 'calibration.p', output_status=True)\n",
    "calibration.calibrate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Plot Calibration Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "for index, filename in enumerate(glob.glob(calibration.images_glob)):\n",
    "    img = cv2.imread(filename)\n",
    "    img_size = (img.shape[1], img.shape[0])\n",
    "    warped, M = corners_unwarp(\n",
    "        img, \n",
    "        PATTERN_SIZE[0], \n",
    "        PATTERN_SIZE[1], \n",
    "        calibration.camera_matrix, \n",
    "        calibration.distortion_coefficients\n",
    "    )\n",
    "    \n",
    "    if warped is None:\n",
    "        continue\n",
    "        \n",
    "    f, (ax1, ax2) = plt.subplots(1, 2, figsize=(20,10))\n",
    "    ax1.imshow(img)\n",
    "    ax1.set_title('Original Image', fontsize=30)\n",
    "    ax2.imshow(warped)\n",
    "    ax2.set_title('Undistorted Image', fontsize=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Demonstrate Perspective Shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "filename = 'test4'\n",
    "image = cv2.imread('../test_images/' + filename + '.jpg')\n",
    "undistorted = cv2.undistort(image, calibration.camera_matrix, calibration.distortion_coefficients, None)\n",
    "transformed_image = warp_birds_eye(\n",
    "    undistorted, \n",
    "    source_points=SOURCE_POINTS, \n",
    "    destination_points=DESTINATION_POINTS\n",
    ")\n",
    "\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(20,10))\n",
    "\n",
    "source_points = np.concatenate( (SOURCE_POINTS, SOURCE_POINTS[:1]), axis=0 )\n",
    "destination_points = np.concatenate( (DESTINATION_POINTS, DESTINATION_POINTS[:1]), axis=0 )\n",
    "\n",
    "ax1.imshow(cv2.cvtColor(undistorted, cv2.COLOR_BGR2RGB))\n",
    "ax1.plot(*zip(*source_points), 'r-')\n",
    "ax2.imshow(cv2.cvtColor(transformed_image, cv2.COLOR_BGR2RGB))\n",
    "ax2.plot(*zip(*destination_points), 'b-')\n",
    "\n",
    "ax1.set_title('Original Image', fontsize=30)\n",
    "ax2.set_title('Undistorted Image', fontsize=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def plot_lanes(ax, fit_left, fit_right):\n",
    "    print(leftx.shape, rightx.shape)\n",
    "    ploty = np.linspace(0, 719, num=720)# to cover same y-range as image\n",
    "\n",
    "    leftx = leftx[::-1]  # Reverse to match top-to-bottom in y\n",
    "    rightx = rightx[::-1]  # Reverse to match top-to-bottom in y\n",
    "\n",
    "    left_fit = np.polyfit(ploty, leftx, 2)\n",
    "    left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "    right_fit = np.polyfit(ploty, rightx, 2)\n",
    "    right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "\n",
    "    # Plot up the fake data\n",
    "    mark_size = 3\n",
    "    ax.plot(leftx, ploty, 'o', color='red', markersize=mark_size)\n",
    "    ax.plot(rightx, ploty, 'o', color='blue', markersize=mark_size)\n",
    "    ax.xlim(0, 1280)\n",
    "    ax.ylim(0, 720)\n",
    "    ax.plot(left_fitx, ploty, color='green', linewidth=3)\n",
    "    ax.plot(right_fitx, ploty, color='green', linewidth=3)\n",
    "    ax.gca().invert_yaxis() # to visualize as we do the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "filenames = glob.glob('../test_images/*.jpg')\n",
    "\n",
    "for image in [ cv2.imread(filename) for filename in filenames ]:\n",
    "    \n",
    "    result = pipeline(image)[:,:,0]\n",
    "    window, l_points, r_points = sliding_window(result)\n",
    "    \n",
    "    f, (ax1, ax2) = plt.subplots(1, 2, figsize=(24, 24))\n",
    "    f.tight_layout()\n",
    "\n",
    "    ax1.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "    ax2.imshow(result, cmap='gray')\n",
    "    ax2.imshow(window, cmap='gray', alpha=0.2)\n",
    "#     ax2.imshow(r_points)\n",
    "#     ax2.plot(r_points[])\n",
    "    l_x = result[np.where(l_points == 255)[0]]\n",
    "    r_x = result[np.where(r_points == 255)[0]]\n",
    "    left_points = np.zeros_like(result)\n",
    "    left_points[(l_points == 255) & (result == 1)] = 1\n",
    "    right_points = np.zeros_like(result)\n",
    "    right_points[(r_points == 255) & (result == 1)] = 1\n",
    "\n",
    "\n",
    "    left_fit = np.polyfit(np.where(left_points == 1)[1], np.where(left_points == 1)[0], deg=2)\n",
    "    right_fit = np.polyfit(np.where(right_points == 1)[1], np.where(right_points == 1)[0], deg=2)\n",
    "\n",
    "    ploty = np.linspace(0, 719, num=720)# to cover same y-range as image\n",
    "    left_x = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "    ax2.plot(ploty, left_x)\n",
    "    ax2.set_xlim(0, result.shape[1])\n",
    "    ax2.set_ylim(0, result.shape[0])\n",
    "\n",
    "    \n",
    "    ax1.set_title('Original Image', fontsize=40)\n",
    "    ax2.set_title('Pipeline Result', fontsize=40)\n",
    "    \n",
    "#     histogram = result.shape[0] - np.sum(result[np.int(result.shape[0] * 3/4):,:], axis=0)\n",
    "#     ax2.plot(histogram, \"y-\", lw=4)\n",
    "    \n",
    "    plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "filenames = glob.glob('../test_images/*.jpg')\n",
    "\n",
    "for image in [ cv2.imread(filename) for filename in filenames ]:\n",
    "    plt.figure()\n",
    "    undistorted = cv2.undistort(image, calibration.camera_matrix, calibration.distortion_coefficients, None)\n",
    "    pipelined = pipeline(undistorted)\n",
    "    filtered = get_edge_mask(undistorted, return_all_channels=True)    \n",
    "    original_birds_eye = warp_birds_eye(undistorted, SOURCE_POINTS, DESTINATION_POINTS)        \n",
    "    filtered_birds_eye = warp_birds_eye(filtered, SOURCE_POINTS, DESTINATION_POINTS)        \n",
    "    plt.imshow(filtered_birds_eye)\n",
    "\n",
    "#     windows = sliding_window(pipelined[:,:,None])[0]\n",
    "#     plt.imshow(windows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "video_path = '../project_video_short.mp4'\n",
    "output_path = '../output.mp4'\n",
    "tracker = LaneLineTracker(\n",
    "    video_path, \n",
    "    calibration=calibration, \n",
    "    source_points=SOURCE_POINTS, \n",
    "    destination_points=DESTINATION_POINTS, \n",
    "    output_path=output_path\n",
    ")\n",
    "%time tracker.process_video()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
